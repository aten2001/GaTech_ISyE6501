{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1A – Consult lawyers.\n",
    "\n",
    "- Type: expert advice.\n",
    "- Input(s): records of past litigations.\n",
    "- Output(s): probability of a litigation, dollar value of a litigation.\n",
    "- Analytical tool(s): logistic regression, descriptive statistics/regression analysis.\n",
    "\n",
    "In this preliminary phase, the company asks lawyers for an expert judgement. The deliverables are an upper and lower bound for when to lawfully enforce shutoffs (e.g. “a customer might only be shutoff upon failing to pay five consecutive electricity bills”, or “a customer might not be shutoff during Christmas time”, etc.).\n",
    "Also, the lawyers will work closely with the company’s statisticians and data scientists to establish the probability of a litigation. The data scientists will do the bulk of the work by creating a logistic regression model using records of past litigations as inputs. Customers that were shut off and litigated will be coded as 1 and customers that were shut off and did not litigate will be coded as 0 (please note that customers that were never shut down need be excluded from the model to avoid bias). Once estimates are available, the data scientists will figure out with the lawyers whether the model is just right, too conservative, or overly sensitive.\n",
    "When it comes to dollar values of litigations, the company’s data scientists might simply use descriptive statistics (or regression analysis) to put a value on each litigation. Again, lawyers’ advice is crucial to tone down or up estimates based on their qualitative judgement. For instance, it might be that laws have become more lenient with non-payers over time (or will soon became so upon the passing of new regulations), and therefore the use of past observations might downwardly bias estimates. The lawyers might also give advice on whether fines are appropriate and what their amount might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1B – Inventor the workforce.\n",
    "\n",
    "- Input: records of the company’s workforce.\n",
    "- Type: expert advice.\n",
    "- Output(s): breakdown of the company’s workforce; estimates of actual and potential productivity for each worker.\n",
    "\n",
    "This task can be tackled in different ways; however, a quick-and-dirty solution is that of grouping employees by degree level (e.g. high school, graduate, post-graduate), technical versus non-technical specialization, or a combination of the two (e.g. graduate technical, graduate non-technical, etc.).\n",
    "Then, the company will need to determine the actual productivity of each employee. Hiring a consultant, most likely a professional economist, might become necessary at this stage (in-house consulting might be an option if the company has the relevant capabilities). We will not go into the weeds on how this task might be accomplished; in general, a worker’s productivity is defined by the difference between the worker’s salary and the profits attributable to the worker’s activity (i.e. value-added). Let’s suppose that a department consists of five equally skilled employees earning a yearly salary of $\\$100,000$ each, and that the department’s contribution to the firm’s profits is worth a dollar amount of $700,000. The individual productivity would be given in this case by:\n",
    "\n",
    "$$\\$700,000 – \\frac{$100,000 \\cdot 5}{5} = \\$40,000$$\n",
    "\n",
    "The above example is simplistic and does not capture the complexities of a company. In reality, things like “transfer prices” (i.e. inter-departmental value-added) need be estimated, and sometimes individual contributions might be hard to pin down. For instance, what is the value of basic research to a company? More often than not, the benefits of research lie in the far-away future and are hard to tie to current accounting measures. Nonetheless, companies keep investing in R&D because it is essential to maintain/create the company’s competitive advantage. For this reason, the expertise of a professional economist is necessary to come to some reasonable approximations of productivity.\n",
    "We also mentioned that potential productivity needs be estimated. What we mean by “potential” is the potential output of a worker if she was allocated to her best-fit task. Clearly, we would not want to allocate PhD engineers to do shutoffs; instead, we would want them to join the R&D team and deploy cutting edge research. Unfortunately, task mismatches are common within companies and should be minimized as much as possible if they want to operate efficiently (our economist consultant would say “Pareto-efficiently”). The insights of our consultant(s) are very much needed to identify misallocations and latent potential for productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1C. Estimate time taken by a shutoff.\n",
    "\n",
    "Type: quantitative.\n",
    "Input(s): customer records.\n",
    "Output(s): distribution of shutoff time.\n",
    "Analytical tool(s): covariate models.\n",
    "\n",
    "Basically, we will need to assume a distribution for the time taken by a shutoff. We might leverage the covariate models used in reliability engineering. A covariate model expresses one or more parameters of a probability distribution function (PDF) as a function of a vector of covariates. What we need as an input is a distributional assumption for the time taken by a shutoff, which we had no clue about. However, the blueprint suggests that the technological characteristics of the industry should be considered, and our uninformed guess is that the normal or the chi-square distribution might be appropriate in this case, although the assumption will need to be validated by expert advice.\n",
    "Assuming that a normal distribution would do the job, the PDF of the time of a shutoff has the functional form $\\mu(X) +\\sigma z$ where the parameter $\\mu(\\cdot)$ is a function of a vector $X$ of parameters:\n",
    "\n",
    "$$ \\mu(X) = x_1 + \\dots + x_m$$\n",
    "\n",
    "What these parameters might be other than the obvious ones (e.g. distance, daytime versus nighttime, position, etc.) is best left to the expert advice rather than to our guesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Calculate the expected cost of a shutoff.\n",
    "\n",
    "- Type: mixed methods.\n",
    "- Input(s): records of customer payments, probability of a litigation (Step 1A), dollar value of a litigation (Step 1A), distribution of shutoff time (1C).\n",
    "- Output(s): expected cost of a shutoff.\n",
    "- Analytical tool(s): cost-benefit analysis\n",
    "\n",
    "A cost-benefit analysis involves the calculation of all the costs and benefits associated with a shutoff. Before a dollar value can be placed upon them, costs and benefits need be identified, which might require qualitative assessment of the management, the data scientists, and possibly external/internal consultants. Pulling the cart before the horse, we tentatively define the expected cost of shutting off customer $i$ at time $t$ as:\n",
    "\n",
    "$$ E(cost shutoff) = Costs - Benefits\\\\\n",
    "= \\left( p_{it}(litigation_{t}) + \\int_{k=t+1}^{\\infty} bill_{ik}(\\cdot)+c_{it} \\right) - bill_{it}$$\n",
    "\n",
    "where the terms associated with a positive sign represent costs and the terms associated with a negative sign represent benefits. Starting with benefits, $bill_it$ are the savings that the company realizes at time $t$ by shutting down a customer (i.e. the dollar value of the bill). The probability of a litigation $p_{it}$ and the cost associated with it $litigation_{t}$ have been obtained in step 1A. Please note that the subscript on $litigation_{t}$ is $t$ and not $it$ because the cost of a litigation has been established as fixed. While there might be good reasons to fine-tune the model to individual customers, the litigation prcoess appears to be quite standard.\n",
    "Such is not the cumulative sum of the forgone future bills $\\int_{k=t+1}^{\\infty} bill_{ik}(\\cdot)+c_{it}$ that the customer would pay had she not been shut off. The reason why we have to integrate is because lifetime electricity consumption is best thought of as a function (i.e. of age, gender, household size, income, etc.). To properly model $bill_{ik}(\\cdot)$, past records of customer payments might be used jointly with expert input from economist consultants. The cost of a shutoff $c_{it}=E(t)_{it} \\cdot \\bar{w}$ is given by the expected time of a shutoff $E(t)_{it}$ multiplied by the wage rate $\\bar{w}$ of the worker. The latter is assumed to be invariant because the company will be likely drawing from the same pool of low-skilled workers to perform shutoffs. On the contrary, $E(t)_{it}$ can be calculated specifying the predictive characteristics of the customer in the covariate model of step 1C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3A. Customer classification.\n",
    "\n",
    "- Type: quantitative/machine learning.\n",
    "- Input(s): records of customer payments, probability of a litigation (Step 1A), dollar value of a litigation (Step 1A), expected cost of a shutoff (Step 2).\n",
    "- Output(s): number and identifiers of customers be shut off.\n",
    "- Analytical tool(s): generalized hierarchical logistic model.\n",
    "\n",
    "Customers will be classified as {green flags, red flags, yellow flags}. Green flags are all those customers that are extremely likely to pay conditional on their payment history; red flags are customers that are unlikely to pay (conditional on their payment history), and yellow flags are those customers that are somewhat likely to pay (conditional on their payment history).\n",
    "This step might be accomplished in different ways using one of the many classification and clustering techniques available. However, we want to give the company a neat, clear-cut trigger to take shutoff decisions, and possibly one that updates automatically as customer records are entered in the company’s database. Therefore, we propose a generalized hierarchical liner model using a logit link to express a customer’s probability of paying at time $t$ as a function of her payment history. The company’s database is likely to look very much like this extract:\n",
    "\n",
    "| Customer  | Time Period   | Paid Bill |\n",
    "|-----------|---------------|-----------|\n",
    "|   Smith   |    Jan-19     |     1     |\n",
    "|   Smith   |    Feb-19     |     1     |\n",
    "|   Smith   |    Mar-19     |     1     |\n",
    "|  Johnson  |    Jan-19     |     0     |\n",
    "|  Johnson  |    Feb-19     |     0     |\n",
    "|  Johnson  |    Mar-19     |     0     |\n",
    "|   White   |    Jan-19     |     0     |\n",
    "|   White   |    Feb-19     |     1     |\n",
    "|   White   |    Mar-19     |     0     |\n",
    "\n",
    "We observe customers “Smith”, “Johnson”, and “White” at multiple time periods; the data points in which the customers paid their bill (i.e. “Paid Bill”) are coded as 1 and those in which they did not pay are coded as 0. The reason we need a nested model is that each customer (level 2 unit) encompasses multiple payment periods (level 2 unit) and therefore variation is clustered at the level of the individual. For this reason, observations cannot be reasonably treated as independent and the structure of the variance cannot be captured by the OLS assumptions <a href=\"https://us.sagepub.com/en-us/nam/hierarchical-linear-models/book9230\">(Raudenbush & Bryk, 2002)</a>. The probability that a customer pays a bill at time $t$ is given by:\n",
    "\n",
    "$$\\left\\{ \\begin{array}{c}\n",
    "Level\\,1:\\ln{\\frac{p_{it}}{1-p_{it}}}=\\beta_{0i}+\\beta_{1i}winter_{ti}+\\beta_{2i}paid_{t-1i}+\\dots+r_{ti};\\\\\n",
    "Level\\,2:\\beta_{0i}=\\gamma_{00}+\\gamma_{01}age_i+\\gamma_{02}income_i+\\dots+u_{0j};\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "where the vector of time-varying coefficients $\\beta=\\{\\beta_{0i},\\beta_{1i},\\dots\\}$ includes all those factors that pertain to a given time-period (e.g. whether it’s winter or nor, whether the customer paid the bill at the time-period prior to t, and so forth), and the vector $\\beta=\\{\\gamma_{00},\\gamma_{01},\\dots\\}$ includes the individual covariates (e.g. age, income, and so forth) deemed to yield an effect on the probability of fulfilling the bill. The model spits the predicted probability that customer will pay at time t; then, it will be the company to decide where to set the cutoffs. The desirable property of a logistic model is that it gives us flexibility on how to classify observations, as we might loosen or tighten our cutoffs over time based upon changes of the cost of misclassifications. The costs of a misclassification are represented by the cost of a false positive, which can be calculated using the formula devised in step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3B. Determine the number of workers to be allocated to shutoffs.\n",
    "\n",
    "- Type: expert advice/quantitative.\n",
    "- Input(s): breakdown of the company’s workforce (step 1B); estimates of actual and potential productivity for each worker (step 1B); number of customers to be shut off (step 3A).\n",
    "- Output(s): number and identifiers of employees to be allocated to shutoffs.\n",
    "- Analytical tool(s): simulation/scenario modeling.\n",
    "\n",
    "This is really a simulation (or “what-if”) kind of environment, which can be tackled either qualitatively or quantitatively. Let’s say that the company has j workers each with a given skillset as classified in step 1B. In a rather stylized model of the company’s production, the company carries out two activities, shutoffs and everything else. Needless to say, this model does not capture the nuances of the company’s operations but it provides a good starting point. The company has to decide how many workers $s<j$ to allocate shutoffs and how many workers $(j-s)$ to allocate to everything else. An extreme and yet possible allocation is one where $s=0$ and all the workers are allocated to everything else. It is believable that the company could do better by allocating one worker to shutoffs (i.e. $s=1$); the company will keep adding workers to shutoffs until the marginal utility of adding an extra worker outpaces its marginal cost (i.e. the loss in production). It is easy to graph this simple model on an xy-plane with s as x-coordinate and the utility $u_s$ of allocating an extra worker to shutoffs as y-coordinate. The resulting curve is bell-shaped and hits a maximum at $(s^*,u_s^*)$ which is the optimal allocation of workers to shutoffs.\n",
    "All this looks pretty good on paper, but how to actually implement it in reality might not be as easy. In other words, what kind of information does the company need to decently estimate $s^*$? Hopefully, step 1B will have provided us with a decent breakdown of the company’s workforce and accurate estimates of the actual and potential productivity of each worker. Another input will come from step 3A, the number of shutoffs that should be ideally performed at time t. Our taskforce of economists will join forces with our data scientists to model different scenarios, some in which more workers are allocated to shutoffs and some in which less are. Clearly, some trade-offs will be proposed such as “we should really shut off these customers, but we don’t have enough low-skilled workers to economically perform so many shutoffs”. Therefore, the company might decide to undertake less of the planned number of shutoffs because the opportunity cost of taking off workers from other activities is too high.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Optimally allocate workers to shutoffs.\n",
    "\n",
    "- Type: quantitative/machine learning.\n",
    "- Input(s): number and identifiers of customers be shut off (3A), number and identifiers of employees to be allocated to shutoffs (step 3B); \n",
    "- Output(s): optimal shutoff route for each employee.\n",
    "- Analytical tool(s): shortest-path algorithms.\n",
    "\n",
    "This last step is strictly contingent on the figures that came out in steps 3A and 3B and qualifies as purely quantitative/machine learning. The problem can be solved using shortest-path algorithms. For each employee, the algorithm needs return the path and the identifiers of customers to be shut off. We assumed the wage rate to be constant therefore the only variable to be minimized is the total time that it will take to perform the planned shutoffs. The most important constraints for the model are: each shutoff needs be performed by at least and at most one employee; each employee has a maximum of $T$ hours available for shutoffs. Again, we will not go in the weeds of this model but the idea is that the algorithm should assign each employee a number of shutoffs to be performed in a given work day and the shortest path to perform these."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
